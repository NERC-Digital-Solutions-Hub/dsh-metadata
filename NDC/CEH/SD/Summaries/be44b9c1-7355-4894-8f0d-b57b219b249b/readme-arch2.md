# README for code with the paper: PAG et al., "Fighting force and experience combine to determine contest success in a warlike mammal"

## Purpose and scope
- Describes the annotated R codebase used to reproduce analyses from the paper.
- Covers imputation, different analytical approaches (maximum likelihood and Bayesian), and follow-up analyses.
- Notes that data descriptions are in a separate data-description.doc.
- Highlights revision tracking (files with "REVISION" in the filename) and provides a contact for missing files or bugs.

## Code components and workflow
- IMPUTATION_ANALYSIS
  - Imputation_Checking_code: verifies that the imputation process does not bias group weight data.
  - Imputation_Analysis_Code_FINAL: full imputation and analysis pipeline.
  - Bayesian_Analysis: runs Bayesian analysis on the imputed datasets for comparison with ML results.
  - All imputation-related code uses the same data files (pre-imputation datasets and related group and rival data).
- OUTPUT_ANALYSIS
  - IGI_OutputAnalyses: summarizes outputs from the imputation/analysis, and compares Bayesian results to maximum likelihood results.
  - Outputs are organized across multiple dataframes and the following files (example patterns): mod.names.AICs.combined.dataframe.1 to .5; mod.avg.coef.df.1 to .5; var.imp.df.1 to .5; FE.rds; ML_model_output.
- FOLLOW_UP_ANALYSES
  - IGI_FollowUpAnalyses_FINAL: performs the follow-up analyses described in the main text.
  - Uses data files including sensitivity to imputation across multiple replicates and time points, life history, captures, oestrus, and complete pedigree data (historical and updated).

## Data inputs and dependencies
- Pre-imputation data files:
  - pre-imputation_igi_winloss_focalonly_wpregnant
  - pre-imputation_rival_igi_winloss_wpregnant
  - pre-imputation_group_comp_wpregnant
  - pre-imputation_rival_group_comp_wpregnant
  - combined_field_capture_weight_data_wpregnancy
- All pre-imputation data are generated by a data generation process described in the project.
- Outputs and analyses rely on a suite of derived data files created from these inputs.

## Data management and reproducibility
- The codebase is heavily annotated to facilitate re-running analyses.
- Data files and outputs are organized with sequential naming to reflect processing stages and revisions.
- If files are missing or bugs are found, the project contact is PAG (pagreen@ucsb.edu).

## Outputs and interpretation
- Outputs include:
  - Model identification and comparisons (AIC-related dataframes).
  - Coefficient estimates and average coefficients across imputations.
  - Variable importance metrics.
  - Fixed effects and ML model outputs (FE.rds, ML_model_output).
- The workflow enables cross-method comparisons (Bayesian vs ML) and consolidation of results into interpretable formats.

## Data sharing and accessibility
- Data provenance is maintained through explicit input files and documented data generation steps.
- Outputs are organized to allow scrutiny and reuse, aligning with aims to monitor environmental-like analyses through standardized, reproducible workflows and multi-source data integration.