# Understanding Environmental Knowledge Controversies: the Case for Flood Risk Management, 2007-2010

- Overview
  - A RELU-funded, interdisciplinary project examining how flood risk knowledge is produced, standardized, and contested.
  - Uses Competency Groups (CGs) that bring together scientists and local residents to co-produce models and interrogate expert claims.
  - Aims to redistribute expertise, test new modelling approaches (knowledge-theoretic), and transfer lessons to broader environmental risk management.

- Data assets and provenance
  - Data types generated and used across work packages:
    - Semi-structured interviews with flood risk scientists, consultants, and policy-makers; ethnographic observations; archival research.
    - Artefacts mediating knowledge claims: maps, photographs, video footage, policy documents, flood models, and computer code.
    - Modelling outputs: bespoke knowledge-theoretic models (bund-model for Pickering; Overflow for Uckfield), and adapted one-dimensional hydraulic models (e.g., ISIS, HEC-RAS, MIKE11).
    - Public-facing outputs: CGsâ€™ reports, presentations, posters, Prezi visualisations, websites, blogs, and a civic resource archive.
  - Data archiving and preservation:
    - Transcript and model script data submitted to ESRC data archive.
    - Long-term web resource documenting knowledge controversies and CG methodology (Prezi-based; interactive materials).

- Data standards, metadata, and formats
  - Differences between standard 1D hydraulic modeling data and bespoke knowledge-theoretic models require careful metadata about:
    - Data sources (topography, rainfall, river geometry), model assumptions, and scenario definitions.
    - Software tools and versions used (ISIS, HEC-RAS, MIKE11; custom bund- and Overflow-related code).
    - Calibration, validation datasets, and uncertainty characterisation.
  - Artefact metadata should capture provenance, purpose, and context to support reuse and transparency.

- Data sharing, access, and licensing
  - Public-facing outputs (bund-model, CG reports, Prezi visualisations, exhibition materials) are disseminated to communities and practitioners, promoting public engagement with modelling.
  - Sensitive materials (interviews and possibly local data) require appropriate consent, anonymisation, and ethical governance aligned with research protocols.
  - The web/resource archive is intended for broad access to encourage replication, adaptation, and transfer to other environmental controversies.

- Data lifecycle, updates, and versioning
  - Models evolved from planned standard approaches to co-produced, location-specific tools (Bunding; Overflow), necessitating version control and clear documentation of changes in assumptions and parameters.
  - Ongoing updates occurred as demonstration projects progressed (e.g., DEFRA funding, EA/public sector uptake), requiring alignment of datasets and model configurations with new objectives.

- Ethics, consent, and public engagement
  - Research ethics were redefined to treat CG members as individuals with equal claims on materials, not as representatives.
  - "Slow down reasoning" approach required transparent handling of disagreements and inclusion of diverse perspectives, including lay participants.
  - Public dissemination (exhibitions, media coverage) amplified data governance responsibilities to ensure accurate representation and accountability.

- Challenges and risks for Data Stewards
  - Incomplete or evolving user needs and priorities among diverse stakeholders.
  - Timely acquisition of data from data creators (modellers, agencies, and residents) amid bureaucratic processes.
  - Alignment of metadata standards across heterogeneous systems and bespoke models.
  - Managing large, potentially non-interoperable datasets and older databases requiring bespoke solutions.
  - Maintaining data quality and documenting uncertainties in complex, contested policy contexts.
  - Balancing openness with privacy and ethical constraints in public engagement activities.

- Implications for data governance practice
  - Support participatory modelling by capturing rich provenance and context for both standard and bespoke models.
  - Establish robust metadata schemas that cover experiential, theoretical, and data-based knowledge inputs and their negotiations within CGs.
  - Preserve artefacts (maps, photos, videos, transcripts, model code) as part of the data lifecycle to enable future scrutiny, replication, and transfer.
  - Document modelling assumptions, calibration processes, uncertainties, and scenario logic to prevent misrepresentation of provisional knowledge as certitude.
  - Draft clear data sharing and licensing policies that accommodate public engagement outputs while protecting sensitive material.
  - Create mechanisms for long-term archiving of interdisciplinary research products and the associated social and political contexts.

- Takeaways for Data Stewards in environmental knowledge controversies
  - Be prepared to manage both standard datasets and bespoke, co-produced models within a single governance framework.
  - Ensure transparency of uncertainties and the provenance of knowledge claims in policy-relevant outputs.
  - Facilitate dissemination tools and archives that support public engagement, repurposing, and interdisciplinary collaboration.
  - Align ethical protocols with participatory methodologies that treat all participants as equal contributors to data and claims.

- Relevance to practice
  - Demonstrates how data governance must adapt to collaborative, cross-sector modelling and contested environmental issues.
  - Highlights the value of archiving interactive and public-facing data products to sustain learning and enable transfer to other domains.