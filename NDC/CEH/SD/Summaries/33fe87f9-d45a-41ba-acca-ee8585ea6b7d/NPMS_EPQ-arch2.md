# Background

- This policy provides a standard to assess the quality of the National Plant Monitoring Scheme (NPMS) as a source of scientific advice and evidence that is fit for purpose.
- It aligns with The Government Chief Scientific Adviser's Guidelines on the Use of Scientific and Engineering Advice in Policy Making (2010), The Defra Joint Code of Practice for Research (2012), and JNCC EQA Guidance notes.
- Evidence encompasses expert opinion, data, methodologies, results, interpretations, and meta-analyses.
- Quality assurance (QA) comprises processes to ensure outputs meet quality standards, with monitoring and auditing as essential elements; core QA principles are “Fit for purpose” and “Right first time.”

## NPMS Aims

- Detect changes in the quality of priority habitats.
- Help understand why change occurs by identifying pressures and drivers.
- Contribute data for the UK Biodiversity Indicator “C7 Plants of the wider countryside” by measuring changes in plant communities across key habitats.

## Application of EQA to NPMS

- Publications supporting EQA include:
  - Peer-reviewed: e.g., Pescott et al. 2015 on ecological monitoring with citizen science.
  - In preparation: comparative models for interval-censored plant cover data; design of a new UK plant monitoring scheme.
  - Other published pieces: articles in British Wildlife, BSBI News, BSS News.
  - Reports: design and development work for the NPMS (2010–2015) and internal project reports.
- Main elements of NPMS design and implementation (as addressed by EQA questions):
  - Sample stratification and survey design: regular grid plots and linear plot lines, developed with statistical and botanical expert input; random with respect to landscape.
  - Habitat definitions: peer-reviewed by habitat experts.
  - Target species list: objective method for indicator selection; reviewed by project team for bias and suitability for volunteers.
  - Field recording: volunteer-based with variable botanical expertise; three participation levels; training and guidance provided; formal QA of field recording is planned for the future.
  - Data input and verification: online capture with a structured spatial database; species dictionary, timing, locations, habitats, and cover values standardized; automated range checks; botanical expert review for exceptional records.
  - Data publishing: aims to publish data publicly for independent review.
  - Analysis: conducted by experienced quantitative ecologists using R.
  - Reporting: by a project team with botany, statistics, and science communication expertise; dissemination through NPMS newsletter and peer-reviewed journals.

## QA Questions and Responses (Q1–Q5)

- Q1: How were partnership peer-reviewed methods/publications?
  - Involved a workshop with statistical and botanical experts; subsequent design testing via data analysis, field testing with volunteers, and questionnaires.
  - Plot selection and habitat/species indicator choices were peer-influenced; field methods and participant training considered for engagement and retention.
  - Data handling and publishing planned with expert verification and public data sharing.
- Q2: How is appropriate quality assurance applied across processes/outputs based on risk?
  - A project Steering Group oversees the work; external peer review used when risk warrants it; workshops focused on survey design.
- Q3: How are uncertainty, quality, assumptions, and limitations communicated?
  - Outputs are checked by scientists to ensure claims are evidence-based; ongoing external interest provides constructive critique; transparency about uncertainty is expected in publications.
- Q4: How are biases avoided in statistics and other outputs?
  - Robust statistical design enables uncertainty to be estimated through modelling.
- Q5: Is there adequate document tracking and version control?
  - Design work is fully reported; versions are archived and backed up off-site per a CEH Data Management Plan; PRINCE2 project management standards are followed.

## Data Handling, Access, and Publication

- Data capture is online and structured within a spatial database.
- A species dictionary, standardized timing, locations, habitats, and cover values minimize input errors.
- Automated verification checks (e.g., geographic range) and expert verification for complex records.
- Data published publicly to enable independent review; results disseminated via newsletters and peer-reviewed journals.

## Governance and Review

- NPMS work is overseen by a Steering Group.
- External peer review is employed where risk warrants, particularly for design elements (e.g., survey design).
- Outputs undergo scientist review to ensure claims are evidence-supported.

## Annex 1: Methodological Paper Outline (NPMS)

- Introduction (KJW)
  - Address lack of structured observational plant monitoring data; compare with other taxa.
- Rationale, Requirements, Aims (KJW)
  - Outline need for structured data and power to detect change (Pescott et al. 2015).
- Design (KJW/OP)
  - Consultation, pilots; sampling framework; habitat and species selection; field method; plot size/placement; number of plots; recording abundance; timing and visits; relocation/replicate surveys.
- Maximising Volunteer Participation (HN)
  - Recruitment; training and support; launch and coordination; synthesize pilot and 2015 activities.
- Discussion (all)
  - Initial evaluation; participation levels; remote areas; future plans.

## Summary for Analysts Monitoring the Environment

- NPMS is a standards-driven, QA-focused program designed to monitor habitat quality changes and drivers, contributing to biodiversity indicators.
- It relies on standardized, transparent methods for design, data collection (including volunteer contributors), data verification, and public data access.
- QA emphasizes fit-for-purpose outputs, right-first-time delivery, and structured uncertainty reporting, with oversight by a Steering Group and selective external peer review.
- Data handling emphasizes a robust workflow: online structured data capture, validated by dictionaries and checks, with formal expert review for complex records, and open data publication for independent scrutiny.
- The program includes a clear pathway from design and field methods through to analysis (R-based) and dissemination (newsletters and journals), with an annex outlining a comprehensive methodological paper that documents rationale, design decisions, participation strategies, and future plans.