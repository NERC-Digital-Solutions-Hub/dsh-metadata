# Background This policy provides a standard to assess the quality of the National Plant Monitoring Scheme (NPMS) as a source of scientific advice and evidence that is fit for purpose. The policy is compliant with The Government Chief Scientific Adviser's Guidelines on the Use of Scientific and Engineering Advice in Policy Making (2010) and The Defra Joint Code of Practice for Research (2012), and associated JNCC EQA Guidance notes (http://jncc.defra.gov.uk/pdf/jncc_EQAssurancePolicy_12.pdf).

## Purpose and scope
- Establishes quality assurance (QA) standards to ensure NPMS outputs are suitable for policy and scientific use.
- Defines evidence to encompass expert opinion, data, methodologies, results, and interpretations derived from NPMS.
- Aligns with government guidelines and JNCC EQA guidance to verify fitness-for-purpose of NPMS outputs.

## NPMS objectives ( QA-aligned )
- Detect changes in the quality of priority habitats.
- Understand why changes occur (pressures and drivers).
- Contribute data for the UK Biodiversity Indicator 'C7 Plants of the wider countryside' by measuring plant community change across key habitats.

## Application of EQA to NPMS: key components
- Publications and sources underpinning QA:
  - Peer-reviewed articles and in-prep papers on design, models, and monitoring schemes.
  - Public-facing and professional outputs documenting scheme development and results.
- QA questions addressed:
  - Q1: How were partnership-recognized methods and publications developed and peer-reviewed? Includes design, habitat definitions, species indicators, field recording, data input, verification, and dissemination plans.
  - Q2: What level of external review is appropriate for different processes/outputs based on risk? Steering Group oversight; selective external peer review.
  - Q3: How are uncertainties, quality, assumptions, and limitations communicated? Claims are checked against evidence; results open to scrutiny by the wider monitoring community.
  - Q4: How are biases avoided in statistical outputs? Robust design and modelling to estimate uncertainty.
  - Q5: Is document tracking and version control adequate? Design work documented; versions archived and backed up per a Data Management Plan; PRINCE2 standards referenced.

## Data governance, quality, and publication workflow
- Evidence and QA processes:
  - Data are published publicly to enable independent review of NPMS results.
  - Analysis led by experienced quantitative ecologists using R; outputs reviewed by the project team.
- Data management and metadata:
  - Online data capture with structured spatial database integration.
  - Use of a species dictionary, controlled habitat terms, and standardized sample information (vegetation height, cover values).
  - Automated validation (e.g., geographic range checks) and expert verification for high-skill records.
- Documentation and tracking:
  - All design outputs tracked; project management follows off-site backups and PRINCE2 standards.
  - Annex 1 outlines a methodological paper that will undergo peer review to address QA gaps.

## Data collection, management, and verification workflow
- Sampling design and field methods:
  - Regular grid-based plots with additional linear plot lines; design favored for landscape randomness.
  - Habitat definitions and target species selected through expert consultation and project review.
  - Three levels of volunteer involvement to accommodate varying expertise; extensive guidance and training provided.
- Data input and quality checks:
  - Online entry ensures structured data; calendar dates, map-based locations, and standardized terms reduce entry errors.
  - Automated checks for validity; expert verification for complex records.
- Analysis and dissemination:
  - Results analyzed by quantitative ecologists; interpreted by a multi-disciplinary project team.
  - Dissemination through NPMS newsletters and peer-reviewed journals; results accessible for researchers, volunteers, policymakers, and the general public.

## Uncertainty, limitations, and stakeholder communication
- Uncertainty and limitations are anticipated and quantified through statistical modelling.
- Outputs explicitly checked by scientists to ensure claims are evidence-backed.
- Ongoing feedback and external critique are encouraged to improve scheme robustness.

## Governance and leadership structure
- Oversight by a project Steering Group.
- External peer review engaged as needed based on risk assessment.
- Clear roles for scientists, statisticians, and communication specialists within the project team.
- Emphasis on transparency, reproducibility, and engagement with the wider ecological monitoring community.

## Annex 1: Methodological paper (planned outline)
- Introduction: Need for structured plant monitoring data and comparisons with other taxa.
- Rationale and aims: Address lack of structured data; establish power to detect change.
- Design: Sampling, habitat and species selection, field methods, plot specifications, timing, and relocation.
- Maximizing volunteer participation: Recruitment, training, and coordination strategies.
- Discussion: Early evaluation, participation levels, remote-area coverage, and future plans.

## Relevance for Data Leaders
- Demonstrates a structured, auditable QA framework aligning data collection, processing, and dissemination with policy needs.
- Emphasizes rigorous governance (Steering Group, external reviews), transparent version control, and a formal Data Management Plan.
- Highlights the importance of clear data provenance, metadata standards, and public data availability to enable independent validation and broader impact.
- Shows how to balance scientific robustness with volunteer-driven data collection and stakeholder engagement.