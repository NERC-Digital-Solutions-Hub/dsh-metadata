# Field practices and biosecurity blackboard post-training survey

## Purpose and scope
- A post-training survey to assess field practices and biosecurity awareness among participants.
- Administered anonymously for research by the University of Leeds; responses can be used for future research.
- Aims to understand fieldwork practices, biosecurity measures, risk perceptions related to invasive non-native species (INNS), and how training/e-learning supports researchers.

## Data collected and structure
- Demographic and background data:
  - Consent to anonymous data use; gender, age, role, and disciplinary area.
  - Role at institution and specific student/academic/employee categories.
- Field practices and environments:
  - Field environments and sites visited per week; number of sites per day; typical modes of arrival.
- Field activities and equipment:
  - Activities conducted (monitoring, sampling, conservation, social research methods, etc.); equipment usage; cleaning and drying routines; field transport and site-to-site equipment use.
- Biosecurity and INNS:
  - Perceived risk of INNS spreading; required risk assessments; familiarity with guidance/campaigns; training participation.
  - Questions about planning to avoid INNS spread, measures taken in field activities, and supervision practices.
- Training and usefulness:
  - Perceived usefulness of the e-learning module and its relevance to research.
- Open responses:
  - Free-text fields for names, email address, and comments about the survey (currently no responses).

## Data quality and completeness
- Very high non-response in many questions (most options show zero responses).
- This results in an incomplete data picture and limited ability to perform analyses across variables such as demographics, field practices, and INNS risk management.
- Structure supports both quantitative (multi-select and Likert-like scales) and qualitative (open text) analysis, but data readiness depends on respondent engagement.

## Privacy, consent, and governance
- Clear consent for anonymous use of responses; emphasis on anonymity for research purposes.
- Potential identifiers in fields like name and email need de-identification or separate handling to maintain anonymity.
- No storage/sharing policies stated; Data Stewards should ensure secure storage, controlled access, and de-identification before any sharing.

## Storage, metadata, and accessibility
- No explicit storage or metadata framework described.
- Data Stewards should implement:
  - A repository with version control and access controls.
  - A data dictionary/codebook detailing variable names, response options, coding schemes, and any skip logic.
  - Documentation of consent, date of collection, population, and instrument version.

## Implications for data governance
- Diverse data types (categorical, ordinal scales, and open-ended responses) require consistent coding and metadata standards.
- Non-response highlights the need for engagement strategies and potential improvements to survey design (mandatory vs. optional items, clarifications, skip patterns).
- Biosecurity and INNS-related questions offer opportunities for standardized risk assessment data, if properly populated.

## Recommendations for Data Stewards
- Improve survey design and outreach to boost response rate and data completeness (clear definitions, mandatory fields where appropriate, and reminders).
- Develop a detailed codebook and data dictionary to ensure consistent coding across responses and future surveys.
- Establish data privacy safeguards:
  - Remove or securely separate direct identifiers (name, email) from the public dataset.
  - Maintain a separate consent log linking participants to identifiers if necessary, with restricted access.
- Create a robust metadata framework:
  - Document instrument name/version, date of collection, population scope, and response rates.
  - Include information on sampling frame and any non-response analysis.
- Plan data cleaning and imputation strategies for incomplete data, and predefine handling rules for “Not applicable” responses and missing values.
- Enable downstream analyses by standardizing field names and response categories (e.g., map seasonal timing, site counts, and INNS risk scales to consistent codes).
- Use findings to inform governance improvements:
  - Align field practice data collection with wider data governance standards.
  - Integrate INNS risk data into broader environmental risk management datasets where appropriate.
- Propose follow-up survey cycles with improved prompts, feedback loops, and demonstration of how responses drive practice changes.