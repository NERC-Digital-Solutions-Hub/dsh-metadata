# Quality Assurance and Evidence Evaluation Policy for the National Plant Monitoring Scheme (NPMS)

## Purpose, compliance and definitions
- Establishes a standard to assess the quality of NPMS as a source of scientific advice and evidence fit for purpose.
- Compliant with: Government Chief Scientific Adviser's Guidelines on the Use of Scientific and Engineering Advice in Policy Making (2010); Defra Joint Code of Practice for Research (2012); and JNCC EQA Guidance notes.
- Evidence basis includes expert opinion, data, methodologies, results, interpretations, and meta-analyses.
- Quality assurance (QA) covers processes to ensure outputs are fit for purpose and produced right first time.

## NPMS Aims
- Detect change in the quality of priority habitats.
- Understand why change is occurring (pressures and drivers).
- Contribute data for the UK Biodiversity Indicator C7 (Plants of the wider countryside) by measuring change in plant communities across key habitats.

## Application of external quality assurance (EQA) to NPMS
- Supported by a suite of publications and reports, including peer-reviewed articles, ongoing research papers, and internal/partners’ reports.
- Questions addressed in the context of NPMS objectives focus on how methods are peer-reviewed, how quality is assured, and how results are interpreted and communicated.

## Key QA mechanisms and processes (mid-document details)
- Design and methods:
  - Sample stratification and survey design developed with statistical and botanical experts; use of a regular grid of plots plus linear plot lines to ensure randomness relative to landscape.
  - Habitat definitions developed through peer review with habitat experts.
  - Target species list derived from an objective method aimed at reducing bias and ensuring practical engagement for volunteers.
- Field recording and data handling:
  - Volunteers with varying botanical expertise contribute; three participation levels with corresponding guidance and training.
  - No formal field recording QA currently, but it will be considered in coming years.
  - Data input uses online capture into a spatial database; a species dictionary, date entries, map-based locations, controlled terms for habitats and sample info, and a standardized scoring system for cover values.
  - Automated checks (e.g., geographic range tests) and a verification system for expert review of exceptions (via BSBI-affiliated botanists).
- Data publishing and analysis:
  - Data will be publicly available to enable independent review.
  - Analyses performed by experienced quantitative ecologists using R scripts.
  - Results reported by a project team with botany, statistics, and science communication expertise; dissemination through NPMS newsletters and peer-reviewed journals.
- Governance and reporting:
  - Steering Group oversees the project; external peer review used as needed based on risk.
  - Outputs checked by scientists to ensure claims are evidence-supported; ongoing critique from broader CEH monitoring communities anticipated.
  - Documentation and version control: all design outputs are archived; off-site backups; managed according to a CEH Data Management Plan and PRINCE2 project management standards.

## How uncertainties, limitations, and biases are handled (Q1–Q5 context)
- Q1: Peer review and collaboration details:
  - Design and methods refined via expert workshops; multiple stages of testing (data analysis, field testing, questionnaires) inform the final survey approach.
  - Habitat indicators chosen to avoid bias and to be suitable for volunteer engagement.
- Q2: Determining review level and risk-based QA:
  - Oversight by Steering Group; external peer review invoked for higher-risk elements (e.g., survey design).
- Q3: Communicating uncertainty and limitations:
  - Outputs reviewed to ensure statements are evidence-based; openness to external critique from ecologists within CEH.
- Q4: Avoiding biases in statistics:
  - Robust statistical design allows uncertainty to be estimated through models applied to data.
- Q5: Documentation and version control:
  - Comprehensive design reporting; versioned documents archived and backed up per Data Management Plan; adherence to PRINCE2 standards.

## Data accessibility and ongoing improvement
- Public data access planned to support transparency and independent validation.
- Formal QA of field recording remains a planned development area; continuous improvement through expert input, testing, and stakeholder engagement.

## endnotes
- The NPMS QA framework integrates collaborative design, rigorous but evolving QA practices, transparent reporting, and data sharing to ensure the scheme’s outputs are reliable for informing policy and biodiversity indicators.