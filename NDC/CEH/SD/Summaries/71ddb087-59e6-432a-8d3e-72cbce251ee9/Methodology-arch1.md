# River Wensum Water Quality Data (2010 - 2016)

- Study design and sampling
  - 20 sampling sites: 17 tributary outlets and 3 main river sites across the River Wensum catchment.
  - Approximately monthly sampling from October 2010 to September 2016.
  - Total samples collected: 899.
  - Sample collection method: river water grabbed from the channel center into 1 L acid pre-washed bottles, transported in cool boxes, and stored at 4Â°C within 5 hours to minimise degradation.
  - Figure reference: locations of the 20 sampling sites.

- Laboratory analysis and quality assurance
  - Analytes measured: nutrients, carbon, major ions, and total suspended solids (TSS).
  - QA procedures:
    - Use of certified reference materials to test instrument accuracy and limits of detection.
    - Instrument precision checked via repeat measurements; non-conforming runs reanalysed after recalibration.
    - Manual data checks for errors before acceptance.
  - Analysis window: all samples analysed within five days of collection.

- The dataset: metadata and analytical methods
  - Metadata details (key fields):
    - Spatial/temporal: latitude/longitude (decimal degrees), date/time (YYYY/MM/DD:HH:MM).
    - Core water quality parameters: pH, electrical conductivity (EC), major cations (Ca, Mg, Na, K), major anions (SO4, Cl, CO3/ HCO3, etc.), total alkalinity, dissolved inorganic species (NO3, NO2, NH4+, TN, TDN, DON), phosphorus species (TP, TDP, TRP, TPP, TNP, PO4 3-), carbon (TC, TOC), total suspended solids (TSS), and related ion balances.
    - Data quality fields: long-term precision and accuracy where provided, limits of detection where applicable, and notes of missing values (N/A) for some metrics.
  - Instruments and platforms used (analytical instruments and models):
    - Metrohm 855 robotic titro sampler.
    - Agilent ICP-OES Vista Pro.
    - Dionex ICS2000 Ion Chromatography.
    - Skalar San ++ Autoanalyser.
    - Skalar Formacs CA15 TOC TN analyser.
  - Data quality and consistency notes:
    - Instrument accuracy and precision validated per batch with reference materials.
    - Recalibration and reanalysis performed for out-of-tolerance runs.
    All data subjected to manual verification prior to acceptance.
  - Data structure and accessibility:
    - The dataset is documented with a comprehensive metadata table and a data dictionary (including units, instruments, precision/accuracy, and detection limits).
    - Aimed at making datasets discoverable and usable, with provenance and measurement details tracked.